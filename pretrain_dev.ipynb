{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224bc54e-fbfc-43ff-af27-57ded4531bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PJRT_DEVICE=TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a29f10f-38b0-46b7-8982-304114a4d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8535, -0.0823, -0.2653],\n",
      "        [-0.0051,  1.3175, -0.5839],\n",
      "        [-1.2089,  1.2293,  1.3118]], device='xla:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "\n",
    "dev = xm.xla_device()\n",
    "t1 = torch.randn(3,3,device=dev)\n",
    "t2 = torch.randn(3,3,device=dev)\n",
    "print(t1 + t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fab52c-9d61-4c71-a21e-8ee0e5f501d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb9085d-6863-4f96-aca2-dd0941112aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    TrainingArguments,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator, DataLoaderConfiguration, DistributedType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa81d274-fa2d-433e-ab61-cb2c62b5c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import IterableDataset, get_worker_info, DataLoader\n",
    "\n",
    "from dataset import StatefulShardedDataset, EvaluationShardedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b666a19f-008e-4a65-a5c5-4cff90ac59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_SEED = 42\n",
    "torch.manual_seed(TOP_SEED)\n",
    "\n",
    "base = '/home/shuyaoli/llm_data/converted_dataset'\n",
    "domain_dirs = {\n",
    "    'book':        os.path.join(base, 'book'),\n",
    "    'arxiv':       os.path.join(base, 'arxiv'),\n",
    "    'stackexchange':os.path.join(base, 'stackexchange'),\n",
    "    'wiki':        os.path.join(base, 'wiki'),\n",
    "    'c4-rp':       os.path.join(base, 'c4-rp'),\n",
    "    'cc':          os.path.join(base, 'cc'),\n",
    "    'github':      os.path.join(base, 'github'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f4cfdf-9646-466d-b3d7-3cb91c063876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ad7ea5-6f6a-4384-b420-959fcfebcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from callback import DynamicSamplingOnEvaluationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78528f-2774-4ae3-9e26-5c451bab024e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d1c99e4-0d08-40b2-a05e-4d1109d93b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_xla.debug import metrics\n",
    "from torch_xla.distributed.parallel_loader import MpDeviceLoader\n",
    "class StreamingTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        # 1) Build a standard DataLoader that uses your HF data_collator\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.per_device_train_batch_size,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "            collate_fn=self.data_collator,            # ← ensures input_ids, attention_mask, labels\n",
    "            pin_memory=False,                         # no pinned memory on TPU\n",
    "            generator=torch.Generator().manual_seed(self.args.seed),\n",
    "            persistent_workers=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        # 2) Wrap it so that every batch is moved onto the TPU device\n",
    "        return MpDeviceLoader(train_loader, device=self.args.device)\n",
    "\n",
    "    def get_eval_dataloader(self, eval_dataset=None):\n",
    "        ds = eval_dataset or self.eval_dataset\n",
    "        if ds is None:\n",
    "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
    "        eval_loader = DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.args.per_device_eval_batch_size,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "            collate_fn=self.data_collator,            # ← again, to get labels for eval loss\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator().manual_seed(self.args.seed + 1),\n",
    "            persistent_workers=True,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        return MpDeviceLoader(eval_loader, device=self.args.device)\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch):\n",
    "        # run one step\n",
    "        out = super().training_step(model, inputs, num_items_in_batch)\n",
    "\n",
    "        # on the very first step, dump some debug info:\n",
    "        if self.state.global_step == 0:\n",
    "            xm.master_print(\"### TPU CHECK ###\")\n",
    "            xm.master_print(\"  XLA devices:\", xm.get_xla_supported_devices())\n",
    "            xm.master_print(\"  Current device:\", xm.xla_device())\n",
    "            xm.master_print(\"  Batch on device:\", inputs['input_ids'].device)\n",
    "            xm.master_print(\"  Model on device:\", next(model.parameters()).device)\n",
    "            xm.master_print(\"  TPU config:\", os.environ.get(\"XRT_TPU_CONFIG\"))\n",
    "            xm.master_print(metrics.metrics_report())\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "655e601d-a4ce-49cb-9aed-d6d2ce29e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_EVAL_BATCH_SIZE = 8\n",
    "EVAL_PATH = '/home/shuyaoli/llm_data/converted_dataset/eval_merge'\n",
    "eval_dataset = EvaluationShardedDataset(\n",
    "    EVAL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aaff8f0-a40b-4dd7-b68e-df01544d763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882968a8-e02e-40d2-89af-5fe9c38e3d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 7 domains.\n",
      "  -> Found 7 shards for domain 'book'\n",
      "  -> Found 4 shards for domain 'arxiv'\n",
      "  -> Found 4 shards for domain 'stackexchange'\n",
      "  -> Found 7 shards for domain 'wiki'\n",
      "  -> Found 23 shards for domain 'c4-rp'\n",
      "  -> Found 103 shards for domain 'cc'\n",
      "  -> Found 7 shards for domain 'github'\n"
     ]
    }
   ],
   "source": [
    "initial_weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "\n",
    "# Instantiate your master dataset\n",
    "master_train_dataset = StatefulShardedDataset(\n",
    "    domain_dirs=domain_dirs,\n",
    "    initial_weights=initial_weights,\n",
    "    chunk_size=4  # small for demo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac683d1-8a92-4e83-9256-183fe8dc3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Sheared-LLaMA model for continued pretraining.\n",
    "model_name = \"princeton-nlp/Sheared-LLaMA-1.3B-Pruned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b773384e-7f3f-4bed-9e8b-ede5ddfad10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to be logged into your Hugging Face account and have\n",
    "# access to meta-llama models for this to work.\n",
    "# `huggingface-cli login`\n",
    "tokenizer_name = \"meta-llama/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca1cbaf-72e5-4910-bf40-07a955881130",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "# Set pad token to EOS token for Causal LM\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df537da5-5d61-4f6b-8180-f4bfc371ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tpu_eval_sampling_model\",\n",
    "    max_steps=5000,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_steps=100,\n",
    "    \n",
    "    # --- Crucial for this strategy ---\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=2, # Run evaluation every 1000 steps\n",
    "    # ---------------------------------\n",
    "    \n",
    "    dataloader_num_workers=30, \n",
    "    remove_unused_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fdd939a-5b4f-4319-85b9-4925896803a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sampling_callback = DynamicSamplingOnEvaluationCallback(\n",
    "    dataset=master_train_dataset,\n",
    "    weight_update_fn=lambda x: 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f52c6b-5c78-4da3-b5fa-22076beed006",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = StreamingTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=master_train_dataset,\n",
    "    eval_dataset=eval_dataset, # Provide the evaluation dataset\n",
    "    callbacks=[eval_sampling_callback], # Use the new callback\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4743be-e986-4910-a771-3c6f725f5d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[ 5809, 29908,   921,  ...,   829,  2271, 29958],\n",
      "        [  278,   937,   934,  ...,   306,   750,  2715]], device='xla:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='xla:0'), 'labels': tensor([[ 5809, 29908,   921,  ...,   829,  2271, 29958],\n",
      "        [  278,   937,   934,  ...,   306,   750,  2715]], device='xla:0')})\n",
      "xla:0\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(trainer.get_train_dataloader()))\n",
    "print(batch.keys())                     # should include 'input_ids', 'attention_mask', 'labels'\n",
    "print(batch['input_ids'].device)        # should be xla:0 (or your TPU device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eab4c4-cef5-49c9-a140-513c2b96e5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TPU CHECK ###\n",
      "  XLA devices: ['xla:0', 'xla:1', 'xla:2', 'xla:3']\n",
      "  Current device: xla:0\n",
      "  Batch on device: xla:0\n",
      "  Model on device: xla:0\n",
      "  TPU config: None\n",
      "Metric: DeviceLockWait\n",
      "  TotalSamples: 12\n",
      "  Accumulator: 419ms828.489us\n",
      "  ValueRate: 001ms204.326us / second\n",
      "  Rate: 0.0345056 / second\n",
      "  Percentiles: 1%=001.730us; 5%=001.730us; 10%=001.840us; 20%=003.411us; 50%=022.989us; 80%=118.280us; 90%=209ms247.635us; 95%=209ms293.365us; 99%=209ms293.365us\n",
      "Metric: InputOutputAliasCount\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 0.00\n",
      "  ValueRate: 0.00 / second\n",
      "  Rate: 0.0115018 / second\n",
      "  Percentiles: 1%=0.00; 5%=0.00; 10%=0.00; 20%=0.00; 50%=0.00; 80%=0.00; 90%=0.00; 95%=0.00; 99%=0.00\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 220\n",
      "  Accumulator: 412ms256.934us\n",
      "  ValueRate: 924ms494.537us / second\n",
      "  Rate: 493.354 / second\n",
      "  Percentiles: 1%=038.220us; 5%=046.951us; 10%=052.730us; 20%=110.850us; 50%=001ms400.680us; 80%=002ms365.610us; 90%=004ms099.969us; 95%=006ms096.239us; 99%=013ms892.569us\n",
      "Metric: LazyTracing\n",
      "  TotalSamples: 7215\n",
      "  Accumulator: 01s109ms299.856us\n",
      "  ValueRate: 538ms364.913us / second\n",
      "  Rate: 40583.1 / second\n",
      "  Percentiles: 1%=000.680us; 5%=000.980us; 10%=003.170us; 20%=003.770us; 50%=011.010us; 80%=019.610us; 90%=027.760us; 95%=039.390us; 99%=054.820us\n",
      "Metric: TensorToData\n",
      "  TotalSamples: 235\n",
      "  Accumulator: 438ms146.598us\n",
      "  ValueRate: 001ms258.833us / second\n",
      "  Rate: 0.675175 / second\n",
      "  Percentiles: 1%=031.890us; 5%=043.490us; 10%=049.760us; 20%=091.330us; 50%=001ms304.020us; 80%=002ms372.109us; 90%=004ms097.379us; 95%=006ms238.199us; 99%=013ms888.889us\n",
      "Metric: TensorsGraphSize\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 48.00\n",
      "  ValueRate: 0.14 / second\n",
      "  Rate: 0.0115019 / second\n",
      "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=19.00; 80%=21.00; 90%=21.00; 95%=21.00; 99%=21.00\n",
      "Metric: UnwrapXlaData\n",
      "  TotalSamples: 8\n",
      "  Accumulator: 098.837us\n",
      "  ValueRate: 000.284us / second\n",
      "  Rate: 0.0230062 / second\n",
      "  Percentiles: 1%=000.180us; 5%=000.180us; 10%=000.180us; 20%=000.209us; 50%=001.970us; 80%=045.250us; 90%=047.189us; 95%=047.189us; 99%=047.189us\n",
      "Metric: WrapXlaData\n",
      "  TotalSamples: 8\n",
      "  Accumulator: 025.371us\n",
      "  ValueRate: 000.073us / second\n",
      "  Rate: 0.0230061 / second\n",
      "  Percentiles: 1%=000.100us; 5%=000.100us; 10%=000.100us; 20%=000.130us; 50%=000.850us; 80%=002.000us; 90%=020.970us; 95%=020.970us; 99%=020.970us\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 6089\n",
      "Counter: DestroyLtcTensor\n",
      "  Value: 5331\n",
      "Counter: DestroyXlaTensor\n",
      "  Value: 5331\n",
      "Counter: DeviceDataCacheMiss\n",
      "  Value: 10\n",
      "Counter: ExecuteComputation\n",
      "  Value: 4\n",
      "Counter: RegisterXLAFunctions\n",
      "  Value: 1\n",
      "Counter: UncachedCompile\n",
      "  Value: 4\n",
      "Counter: xla::_copy_from\n",
      "  Value: 224\n",
      "Counter: xla::_log_softmax\n",
      "  Value: 1\n",
      "Counter: xla::_log_softmax_backward_data\n",
      "  Value: 1\n",
      "Counter: xla::_propagate_xla_data\n",
      "  Value: 56\n",
      "Counter: xla::_softmax\n",
      "  Value: 24\n",
      "Counter: xla::_softmax_backward_data\n",
      "  Value: 24\n",
      "Counter: xla::_to_copy\n",
      "  Value: 228\n",
      "Counter: xla::_unsafe_view\n",
      "  Value: 218\n",
      "Counter: xla::add\n",
      "  Value: 461\n",
      "Counter: xla::arange_out\n",
      "  Value: 4\n",
      "Counter: xla::bitwise_and\n",
      "  Value: 2\n",
      "Counter: xla::bmm\n",
      "  Value: 145\n",
      "Counter: xla::cat\n",
      "  Value: 49\n",
      "Counter: xla::clone\n",
      "  Value: 2\n",
      "Counter: xla::constant_pad_nd\n",
      "  Value: 1\n",
      "Counter: xla::cos\n",
      "  Value: 1\n",
      "Counter: xla::detach_copy\n",
      "  Value: 439\n",
      "Counter: xla::div\n",
      "  Value: 53\n",
      "Counter: xla::embedding_dense_backward\n",
      "  Value: 1\n",
      "Counter: xla::embedding_symint\n",
      "  Value: 1\n",
      "Counter: xla::empty_strided_symint\n",
      "  Value: 50\n",
      "Counter: xla::empty_symint\n",
      "  Value: 385\n",
      "Counter: xla::expand_copy_symint\n",
      "  Value: 154\n",
      "Counter: xla::fill_\n",
      "  Value: 27\n",
      "Counter: xla::index\n",
      "  Value: 1\n",
      "Counter: xla::le\n",
      "  Value: 1\n",
      "Counter: xla::lift_fresh\n",
      "  Value: 2\n",
      "Counter: xla::mean\n",
      "  Value: 49\n",
      "Counter: xla::mm\n",
      "  Value: 507\n",
      "Counter: xla::mul\n",
      "  Value: 876\n",
      "Counter: xla::ne\n",
      "  Value: 1\n",
      "Counter: xla::neg\n",
      "  Value: 96\n",
      "Counter: xla::nll_loss_backward\n",
      "  Value: 1\n",
      "Counter: xla::nll_loss_forward\n",
      "  Value: 1\n",
      "Counter: xla::normal_\n",
      "  Value: 2\n",
      "Counter: xla::pow\n",
      "  Value: 147\n",
      "Counter: xla::rsqrt\n",
      "  Value: 49\n",
      "Counter: xla::select_copy\n",
      "  Value: 2\n",
      "Counter: xla::sigmoid\n",
      "  Value: 24\n",
      "Counter: xla::silu\n",
      "  Value: 24\n",
      "Counter: xla::sin\n",
      "  Value: 1\n",
      "Counter: xla::slice_copy\n",
      "  Value: 273\n",
      "Counter: xla::slice_scatter\n",
      "  Value: 99\n",
      "Counter: xla::sub\n",
      "  Value: 24\n",
      "Counter: xla::sum\n",
      "  Value: 99\n",
      "Counter: xla::t_copy\n",
      "  Value: 676\n",
      "Counter: xla::transpose_copy\n",
      "  Value: 337\n",
      "Counter: xla::unsqueeze_copy\n",
      "  Value: 54\n",
      "Counter: xla::view_copy_symint\n",
      "  Value: 1218\n",
      "Counter: xla::where\n",
      "  Value: 1\n",
      "Counter: xla::zero_\n",
      "  Value: 99\n",
      "Metric: CompileTime\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 08s979ms294.431us\n",
      "  ValueRate: 023ms944.163us / second\n",
      "  Rate: 0.0115019 / second\n",
      "  Percentiles: 1%=084ms872.924us; 5%=084ms872.924us; 10%=084ms872.924us; 20%=084ms872.924us; 50%=02s158ms411.576us; 80%=06s652ms635.198us; 90%=06s652ms635.198us; 95%=06s652ms635.198us; 99%=06s652ms635.198us\n",
      "Metric: ExecuteTime\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 395ms188.570us\n",
      "  ValueRate: 001ms136.466us / second\n",
      "  Rate: 0.011503 / second\n",
      "  Percentiles: 1%=001ms487.010us; 5%=001ms487.010us; 10%=001ms487.010us; 20%=001ms487.010us; 50%=162ms336.487us; 80%=228ms857.354us; 90%=228ms857.354us; 95%=228ms857.354us; 99%=228ms857.354us\n",
      "Metric: InboundData\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 192.04KB\n",
      "  ValueRate: 618.71B / second\n",
      "  Rate: 0.0125854 / second\n",
      "  Percentiles: 1%=36.00B; 5%=36.00B; 10%=36.00B; 20%=36.00B; 50%=64.00KB; 80%=64.00KB; 90%=64.00KB; 95%=64.00KB; 99%=64.00KB\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 235\n",
      "  Accumulator: 5.02GB\n",
      "  ValueRate: 14.76MB / second\n",
      "  Rate: 0.675175 / second\n",
      "  Percentiles: 1%=4.00B; 5%=256.00B; 10%=8.00KB; 20%=8.00KB; 50%=16.00MB; 80%=43.00MB; 90%=43.00MB; 95%=43.00MB; 99%=43.00MB\n",
      "Metric: TransferFromDeviceTime\n",
      "  TotalSamples: 4\n",
      "  Accumulator: 007ms424.110us\n",
      "  ValueRate: 023.359us / second\n",
      "  Rate: 0.0125854 / second\n",
      "  Percentiles: 1%=759.190us; 5%=759.190us; 10%=759.190us; 20%=759.190us; 50%=002ms751.280us; 80%=004ms679.570us; 90%=004ms679.570us; 95%=004ms679.570us; 99%=004ms679.570us\n",
      "Metric: TransferToDeviceTime\n",
      "  TotalSamples: 235\n",
      "  Accumulator: 035ms863.094us\n",
      "  ValueRate: 100.165us / second\n",
      "  Rate: 0.675175 / second\n",
      "  Percentiles: 1%=020.890us; 5%=025.649us; 10%=028.489us; 20%=030.930us; 50%=039.160us; 80%=082.660us; 90%=161.470us; 95%=391.151us; 99%=004ms143.350us\n",
      "Counter: CreateCompileHandles\n",
      "  Value: 4\n",
      "Counter: CreateDataHandles\n",
      "  Value: 332\n",
      "Counter: MarkStep\n",
      "  Value: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de46ae82-2608-49c5-85c1-23a255fbf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; cpu_count = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea3941-b3ee-4dd2-b20a-b04e0be8ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f4c8b-3a7e-4f2d-b543-2fdc80f0f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6240422-fde5-4602-be02-5123cae7e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = xm.xrt_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24159386-0ff8-47fc-9ece-dfba0279e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.runtime as xr; world_size = xr.world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c53eb3-89ba-4ac1-8ffa-efd3bdde73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab63ef7-7e5f-49eb-b05e-a8a168947ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
